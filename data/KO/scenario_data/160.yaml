metadata:
  total_steps: 11
  note: workflow_id can be None for initial rows
steps:
- workflow_id: system
  step_id: 1
  agent: main
  agent_type: main
  data:
    content: '- date: 2025-07-22'
- workflow_id: null
  step_id: 2
  agent: user
  agent_type: user
  data:
    content: 오늘 LLM 관련 뉴스 있는지 확인해서 브리핑해줘
- workflow_id: null
  step_id: 3
  agent: main
  agent_type: main
  data:
    content: "workflow_1:\n  status: pending\n  type: independent\n  steps:\n    -\
      \ status: pending\n      name: news_agent\n      refined_query: \"오늘 LLM 관련\
      \ 뉴스 브리핑\""
- workflow_id: workflow_1
  step_id: 4
  agent: news_agent
  agent_type: agent
  data:
    content: "tool: summarizeNews\narguments:\n  refinedQuery: \"LLM 관련 뉴스 브리핑\"\n\
      \  topic: \"LLM\"\n  date: \"2025-07-22\"\ntool_call_result:\n  status: success\n\
      \  data:\n    news:\n      - title: \"‘국가대표 AI’ 누가 될까…네이버·카카오·LG·SKT 등 15곳 지원\"\
      \n        url: \"https://v.daum.net/v/20250722111114351\"\n        summary:\
      \ \"정부는 '국가대표 AI'를 선정하여 한국형 거대언어모델(LLM) 개발을 지원하고 AI 기술의 해외 의존도를 낮추는 사업을 추진하고\
      \ 있습니다. 네이버, 카카오 등 총 15개 팀이 이 사업에 지원했으며, 최종 선정되는 5개 팀에게는 GPU, 데이터, 인재 영입 비용\
      \ 등 전폭적인 지원이 제공되어 국내 AI 기술 경쟁력이 한층 더 강화될 것으로 기대됩니다.\"\n      - title: \"LG AI\
      \ 생태계 청사진 나왔다…바이오·금융·반도체 B2B 시장 진출\"\n        url: \"https://v.daum.net/v/20250722141526918\"\
      \n        summary: \"LG AI연구원은 'AI 토크 콘서트 2025'에서 '엑사원 생태계'를 공개하며, 하이브리드 AI\
      \ 모델 '엑사원 4.0'과 기업용 AI 솔루션 등을 선보였습니다. LG는 LSEG, 퓨리오사 AI 등 다양한 파트너와 협력하여 바이오,\
      \ 금융, 반도체 B2B 시장에 본격적으로 진출하며 이미 1000억 원 이상의 수주 성과를 달성했습니다.\"\n      - title:\
      \ \"\\\"해외 빅테크 러브콜? 안 가요\\\"…한국형 '소버린AI', 희망 보인다\"\n        url: \"https://v.daum.net/v/20250722070149337\"\
      \n        summary: \"학계에서는 이번 '독자 AI 파운데이션 모델' 프로젝트가 국내 AI 인재 유출을 막고 세계 최고 수준의\
      \ AI를 개발할 기회라고 기대하지만, 산업계에서는 글로벌 경쟁력을 갖추기 위해 고품질 데이터 확보와 규제 완화 등 해결 과제가 많다고\
      \ 지적합니다. 따라서 정부의 적극적인 지원과 민간 생태계와의 협력을 통해 내수용을 넘어선 글로벌 AI 모델 개발 전략이 필요합니다.\"\
      \n      - title: \"네이버, 하이퍼클로바X 상업용 무료 공개…\\\"생태계 확장\\\"\"\n        url: \"\
      https://v.daum.net/v/20250722120316324\"\n        summary: \"네이버클라우드는 자체 개발한\
      \ 경량화 추론 모델 '하이퍼클로바X SEED 14B Think'를 상업용 무료 오픈소스로 공개하여 국내 AI 기술력을 한 단계 높였습니다.\
      \ 이 모델은 학습 비용을 100분의 1 수준으로 크게 낮추었음에도 불구하고 한국어, 코딩 등에서 우수한 성능을 보여 국내 AI 생태계\
      \ 성장에 기여할 것으로 기대됩니다.\""
- workflow_id: null
  step_id: 5
  agent: main
  agent_type: main
  data:
    content: '오늘의 LLM 주요 뉴스 입니다.


      1. ‘국가대표 AI’ 누가 될까…네이버·카카오·LG·SKT 등 15곳 지원

      정부는 ''국가대표 AI''를 선정하여 한국형 거대언어모델(LLM) 개발을 지원하고 AI 기술의 해외 의존도를 낮추는 사업을 추진하고 있습니다.
      네이버, 카카오 등 총 15개 팀이 이 사업에 지원했으며, 최종 선정되는 5개 팀에게는 GPU, 데이터, 인재 영입 비용 등 전폭적인 지원이
      제공되어 국내 AI 기술 경쟁력이 한층 더 강화될 것으로 기대됩니다.


      - 링크: https://v.daum.net/v/20250722111114351


      2. "해외 빅테크 러브콜? 안 가요"…한국형 ''소버린AI'', 희망 보인다

      학계에서는 이번 ''독자 AI 파운데이션 모델'' 프로젝트가 국내 AI 인재 유출을 막고 세계 최고 수준의 AI를 개발할 기회라고 기대하지만,
      산업계에서는 글로벌 경쟁력을 갖추기 위해 고품질 데이터 확보와 규제 완화 등 해결 과제가 많다고 지적합니다. 따라서 정부의 적극적인 지원과
      민간 생태계와의 협력을 통해 내수용을 넘어선 글로벌 AI 모델 개발 전략이 필요합니다.


      - 링크: https://v.daum.net/v/20250722070149337


      3. LG AI 생태계 청사진 나왔다…바이오·금융·반도체 B2B 시장 진출

      LG AI연구원은 ''AI 토크 콘서트 2025''에서 ''엑사원 생태계''를 공개하며, 하이브리드 AI 모델 ''엑사원 4.0''과 기업용
      AI 솔루션 등을 선보였습니다. LG는 LSEG, 퓨리오사 AI 등 다양한 파트너와 협력하여 바이오, 금융, 반도체 B2B 시장에 본격적으로
      진출하며 이미 1000억 원 이상의 수주 성과를 달성했습니다.


      - 링크: https://v.daum.net/v/20250722141526918


      4. 네이버, 하이퍼클로바X 상업용 무료 공개…"생태계 확장"

      네이버클라우드는 자체 개발한 경량화 추론 모델 ''하이퍼클로바X SEED 14B Think''를 상업용 무료 오픈소스로 공개하여 국내 AI
      기술력을 한 단계 높였습니다. 이 모델은 학습 비용을 100분의 1 수준으로 크게 낮추었음에도 불구하고 한국어, 코딩 등에서 우수한 성능을
      보여 국내 AI 생태계 성장에 기여할 것으로 기대됩니다.


      - 링크: https://v.daum.net/v/20250722120316324'
- workflow_id: null
  step_id: 6
  agent: user
  agent_type: user
  data:
    content: 하이퍼클로바 seed think 모델 성능은 어때? 여러 한국 회사에서 최근 공개된 LLM과 비교해서 알려줘
- workflow_id: null
  step_id: 7
  agent: main
  agent_type: main
  data:
    content: "workflow_1:\n  status: completed\n  type: independent\n  steps:\n  \
      \  - status: completed\n      name: news_agent\n      refined_query: \"오늘 LLM\
      \ 관련 뉴스 브리핑\" \n\nworkflow_2:\n  status: pending\n  type: independent\n  steps:\n\
      \    - status: pending\n      name: search_agent\n      refined_query: \"여러\
      \ 한국 회사에서 최근 공개된 LLM\"\n\nworkflow_3:\n  status: pending\n  type: independent\n\
      \  steps:\n    - status: pending\n      name: search_agent\n      refined_query:\
      \ \"LLM의 주요 성능 지표\"\n\nworkflow_4:\n  status: pending\n  type: dependent\n \
      \ depend_on: [\"workflow_2\", \"workflow_3\"]\n  steps:\n    - status: pending\n\
      \      name: search_agent\n      refined_query: \"여러 한국 회사에서 최근 공개한 LLM과 하이퍼클로바\
      \ seed think 모델의 LLM 주요 성능 지표 검색\""
- workflow_id: workflow_2
  step_id: 8
  agent: search_agent
  agent_type: agent
  data:
    content: "tool: searchInfo\narguments:\n  refinedQuery: \"2025년 7월 22일 기준 최근 한국\
      \ 회사에서 공개한 LLM\"\ntool_call_result:\n  results:\n    - name: \"NAVER HyperCLOVA\
      \ X SEED 14B Think\"\n      org: \"NAVER\"\n      release_date: \"2025-07-22\"\
      \n      parameters: \"14B\"\n      highlights:\n        - HyperCLOVA X THINK를\
      \ 디스틸 및 프루닝한 경량 추론 특화 LLM\n        - 원본 성능 유지하면서도 추론 속도 및 비용 최적화\n        -\
      \ 상업적 용도로도 무료 공개\n      source: \"https://www.asiatoday.co.kr/kn/view.php?key=20250722010012541\"\
      \n    \n    - name: \"SKT A.X 3.1 Light\"\n      org: \"SK Telecom\"\n     \
      \ release_date: \"2025-07 (예정)\"\n      parameters: \"7B\"\n      highlights:\n\
      \        - SKT의 A.X 시리즈 경량 LLM\n        - CLIcK 벤치마크에서 A.X 4.0 대비 102% 성능 기록\n\
      \        - 모바일 등 온디바이스 환경에 최적화됨\n      source: \"https://news.sktelecom.com/213795\"\
      \n    \n    - name: \"LG EXAONE 4.0 32B\"\n      org: \"LG AI Research\"\n \
      \     release_date: \"2025-07\"\n      parameters: \"32B\"\n      highlights:\n\
      \        - 추론 기반 하이브리드 LLM\n        - MMLU-Pro 81.8, GPQA 75.4, AIME 85.3 기록\n\
      \        - Agent 기반 태스크 처리 지원, 128K 문맥 길이\n      source: \"https://www.lgresearch.ai/blog/view?seq=575\"\
      \n    \n    - name: \"Upstage Solar Pro 2\"\n      org: \"Upstage\"\n      release_date:\
      \ \"2025-07\"\n      parameters: \"31B\"\n      highlights:\n        - 한국어 전용\
      \ 고성능 LLM\n        - MMLU-Pro, IFEval 등 다양한 벤치마크에서 GPT-4o 능가\n        - 상용 환경에서\
      \ 빠른 추론 및 도입 최적화\n      source: \"https://blog.upstage.ai/ko/solar-pro-2\"\n\
      \    \n    - name: \"Kakao Kanana 1.5 9.8B\"\n      org: \"Kakao Brain\"\n \
      \     release_date: \"2025-07\"\n      parameters: \"9.8B\"\n      highlights:\n\
      \        - 한국어-영어 bilingual 모델\n        - 긴 문맥 처리, tool usage, 함수 호출 등 기능 강화\n\
      \        - 여러 공개 벤치마크에서 글로벌 SOTA 수준 기록\n      source: \"https://tech.kakao.com/posts/706\""
- workflow_id: workflow_3
  step_id: 9
  agent: search_agent
  agent_type: agent
  data:
    content: "tool: searchInfo\narguments:\n  refinedQuery: \"언어 모델 주요 성능 지표\"\ntool_call_result:\n\
      \  status: success\n  data:\n    metrics:\n      - name: \"MMLU\"\n        full_name:\
      \ \"Massive Multitask Language Understanding\"\n        description: \"57개의\
      \ 다양한 분야(의학, 법률, 수학 등)에 걸쳐 구성된 고등 수준의 다지식 문제를 해결하는 능력을 평가하는 벤치마크\"\n       \
      \ format: \"4지선다 문제, zero-shot 또는 5-shot 설정에서 평가\"\n        widely_used_by:\
      \ [\"OpenAI\", \"Anthropic\", \"Google DeepMind\"]\n        reference_link:\
      \ \"https://github.com/hendrycks/test\"\n\n      - name: \"MMLU-Pro\"\n    \
      \    full_name: \"Professional-level MMLU\"\n        description: \"MMLU의 확장\
      \ 버전으로, 전문 자격증 시험 수준의 고난도 질문들로 구성됨. LLM의 전문적 지식 응답 능력을 평가\"\n        format:\
      \ \"도메인별 문제지 기반, multiple-choice 형식\"\n        widely_used_by: [\"OpenAI GPT-4o\"\
      , \"Claude 3\", \"Command R+\", \"LLaMA 3\"]\n        reference_link: \"https://paperswithcode.com/sota/mmlu-pro\"\
      \n\n      - name: \"KMMLU\"\n        full_name: \"Korean Massive Multitask Language\
      \ Understanding\"\n        description: \"MMLU의 한국어 버전. 한국어로 된 법률, 의학, 한국사,\
      \ 시사 상식 등 다양한 분야의 평가 문항으로 구성\"\n        format: \"4지선다형, 한국어 질문 및 보기\"\n   \
      \     widely_used_by: [\"카카오브레인\", \"NAVER\", \"연구용 K-LLM 벤치마크\"]\n        reference_link:\
      \ \"https://github.com/psyche8975/K-MMLU\""
- workflow_id: workflow_4
  step_id: 10
  agent: search_agent
  agent_type: agent
  data:
    content: "tool_call:\n  - tool: searchInfo\n    arguments:\n      refinedQuery:\
      \ \"HyperCLOVA X SEED 14B Think 모델의 MMLU, MMLU-Pro, KMMLU 결과\"\n  - tool: searchInfo\n\
      \    arguments:\n      refinedQuery: \"SKT A.X 3.1 Light 모델의 MMLU, MMLU-Pro,\
      \ KMMLU 결과\"\n  - tool: searchInfo\n    arguments:\n      refinedQuery: \"LG\
      \ EXAONE 4.0 32B 모델의 MMLU, MMLU-Pro, KMMLU 결과\"\n  - tool: searchInfo\n    arguments:\n\
      \      refinedQuery: \"Upstage Solar Pro 2 모델의 MMLU, MMLU-Pro, KMMLU 결과\"\n\
      \  - tool: searchInfo\n    arguments:\n      refinedQuery: \"Kakao Kanana 1.5\
      \ 9.8B 모델의 MMLU, MMLU-Pro, KMMLU 결과\"\n\ntool_call_result:\n  - status: success\n\
      \    data:\n      mmlu: 0.7121\n      mmlu_pro: N/A\n      kmmlu: 0.6649\n \
      \     references:\n        - \"https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Think-14B\"\
      \n  - status: success\n    data:\n      mmlu: 0.6695\n      mmlu_pro: 0.4554\n\
      \      kmmlu: 0.617\n      references:\n        - \"https://huggingface.co/skt/A.X-3.1-Light\"\
      \n  - status: success\n    data:\n      mmlu: 0.923\n      mmlu_pro: 0.818\n\
      \      kmmlu: 0.727\n      references:\n        - \"https://arxiv.org/pdf/2507.11407\"\
      \n  - status: success\n    data:\n      mmlu: 0.8816\n      mmlu_pro: 0.7652\n\
      \      kmmlu: 0.7704\n      references:\n        - \"https://www.upstage.ai/blog/ko/solar-pro-2-launch\"\
      \n  - status: success\n    data:\n      mmlu: 0.6827\n      mmlu_pro: N/A\n\
      \      kmmlu: 0.5278\n      references:\n        - \"https://github.com/kakao/kanana\""
- workflow_id: null
  step_id: 11
  agent: main
  agent_type: main
  data:
    content: '하이퍼클로바 SEED Think 모델은 14B 규모의 경량 LLM으로, 한국어와 일반 지식 기반 벤치마크에서 중상위 수준의
      성능을 보입니다.


      [주요 국산 LLM들과의 성능 비교]


      | 모델                          |   MMLU | MMLU-Pro   |   KMMLU |

      |:----------------------------|-------:|:-----------|--------:|

      | HyperCLOVA X SEED 14B Think | 0.7121 | N/A        |  0.6649 |

      | SKT A.X 3.1 Light           | 0.6695 | 0.4554     |  0.617  |

      | LG EXAONE 4.0 32B           | 0.923  | 0.818      |  0.727  |

      | Upstage Solar Pro 2         | 0.8816 | 0.7652     |  0.7704 |

      | Kakao Kanana 1.5 9.8B       | 0.6827 | N/A        |  0.5278 |'
