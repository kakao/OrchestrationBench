"""
Google Gemini model implementation.

This module provides an interface to Google's Gemini models using the new 'google.genai' SDK.
"""

from typing import Dict, List, Any, Optional, Callable
import copy
import google.genai as genai
from google.genai import Client
from google.genai import types # Corrected import for GenerationConfig, ChatSession, etc.
from loguru import logger

from src.models.base_model import BaseModel # Assuming BaseModel remains the same
from google.genai.types import GenerationConfig, Content, Part, Tool # Importing types from the new SDK

class GeminiModel(BaseModel):
    """Google Gemini model implementation using the new google.genai SDK."""
    
    def __init__(
        self,
        model_name: str = "gemini-1.5-pro", 
        temperature: float = 0.7,
        max_tokens: int = 4096,
        google_api_key: Optional[str] = None,
        token_callback: Optional[Callable[[str, int, int, float], None]] = None,
        **kwargs
    ):
        """Initialize Gemini model."""
        super().__init__(model_name, temperature, max_tokens, token_callback, **kwargs)
        self.client: Optional[Client] = None # The new Client object
        self.api_key = google_api_key
    
    async def initialize(self) -> None:
        """Initialize the Gemini client."""
        if not self.api_key:
            raise ValueError("Google API key not provided")
        
        try:
            self.client = genai.Client(api_key=self.api_key)
            # Test the connection using the client
            await self.check_availability()
            self.initialized = True
            logger.info(f"Gemini model {self.model_name} initialized successfully with new SDK")
        except Exception as e:
            logger.error(f"Failed to initialize Gemini model with new SDK: {e}")
            raise


    def clean_and_convert_to_declarations(self, raw_tools):
        """
        ì›ëž˜ íˆ´ ìŠ¤í‚¤ë§ˆë¥¼ Gemini APIê°€ ìš”êµ¬í•˜ëŠ” í•¨ìˆ˜ ì„ ì–¸ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        - `oneOf` ë˜ëŠ” ë³µìˆ˜ íƒ€ìž…ì„ `STRING`ìœ¼ë¡œ ë‹¨ìˆœí™”í•˜ê³  ì„¤ëª…ì„ ë™ì ìœ¼ë¡œ ì¡°í•©í•©ë‹ˆë‹¤.
        - APIì—ì„œ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì†ì„±ì„ ì œê±°í•˜ê³ , `type`ì„ ëŒ€ë¬¸ìžë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        """
        tools_copy = copy.deepcopy(raw_tools)
        
        declarations = []
        for raw_tool in tools_copy:
            function_def = raw_tool.get('function')
            if not function_def:
                continue

            parameters = function_def.get('parameters', {})
            properties = parameters.get('properties', {})

            # ðŸ’¡ [í•µì‹¬ ìˆ˜ì • ë¡œì§] ë¬¸ì œê°€ ë˜ëŠ” í”„ë¡œí¼í‹°ë“¤ì„ ë¨¼ì € ìˆ˜ì •í•©ë‹ˆë‹¤.
            for prop_name, prop_value in properties.items():
                # Case 1: 'oneOf' í‚¤ê°€ ëª…ì‹œì ìœ¼ë¡œ ìžˆëŠ” ê²½ìš°
                if 'oneOf' in prop_value:
                    descriptions = [
                        item.get('description', '') 
                        for item in prop_value.get('oneOf', []) 
                        if item.get('description')
                    ]
                    new_description = " í˜¹ì€ ".join(descriptions)
                    
                    properties[prop_name] = {
                        'type': 'string',
                        'description': new_description
                    }
                # Case 2: 'type'ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (['string', 'object'])
                elif isinstance(prop_value.get('type'), list):
                    original_desc = prop_value.get('description', '')
                    format_instruction = " (ì¢Œí‘œëŠ” 'lat:ìœ„ë„,lng:ê²½ë„' í˜•ì‹ì˜ ë¬¸ìžì—´ë¡œ ì œê³µ)"
                    
                    properties[prop_name] = {
                        'type': 'string',
                        'description': original_desc + format_instruction
                    }
                
                elif 'date' in prop_name.lower():
                    prop_value['format'] = 'date-time'

            # ìž¬ê·€ì ìœ¼ë¡œ ì „ì²´ ìŠ¤í‚¤ë§ˆë¥¼ ì •ë¦¬í•˜ê³  íƒ€ìž…ì„ ëŒ€ë¬¸ìžë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
            def recursive_clean(schema_node):
                if isinstance(schema_node, list):
                    return [recursive_clean(item) for item in schema_node]
                
                if not isinstance(schema_node, dict):
                    return schema_node

                cleaned_node = {}
                for key, value in schema_node.items():
                    if key in ['additionalProperties', 'default'] and value in [False, None]:
                        continue
                    elif key == 'type' and isinstance(value, str):
                        cleaned_node[key] = value.upper()
                    else:
                        cleaned_node[key] = recursive_clean(value)
                return cleaned_node

            declarations.append(recursive_clean(function_def))
            
        return declarations
    
    async def generate_response(
        self,
        prompt: str,
        system_prompt: Optional[str] = None,
        **kwargs
    ) -> str:
        """Generate a response using Gemini's API with the new SDK."""
        if not self.client:
            raise RuntimeError("Model not initialized. Call initialize() first.")
        
        # Check budget before making request
        if not self.check_budget():
            raise RuntimeError(f"Budget limit exceeded. Used: {self.budget_used}, Limit: {self.budget_limit}")
        
        try:
            if 'tools' in kwargs:
                tools = kwargs['tools']
            else:
                tools = []
            # Configure generation parameters
            function_declarations_list = self.clean_and_convert_to_declarations(tools)
            converted_tools = Tool(function_declarations=function_declarations_list)

            config = types.GenerateContentConfig(tools=[converted_tools], 
                                                temperature=self.temperature,
                                                system_instruction=system_prompt if system_prompt else None
            )

            contents = [types.Part(text=prompt)]
             
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=contents,
                config=config,
            )

            content = response.text
            return_format = {"role":"assistant", "content": content if content is not None else "\n\n"}
            if response.function_calls is not None:
                tool_calls = []
                for cnt, fn in enumerate(response.function_calls):
                    tool_calls.append(self.convert_function_call_to_tool_call(fn, cnt))
                return_format["tool_calls"] = tool_calls

            input_tokens = len(prompt.split()) * 1.3
            if system_prompt:
                input_tokens += len(system_prompt.split()) * 1.3
            output_tokens = len(content.split()) * 1.3
            self._update_stats(int(input_tokens), int(output_tokens))
            
            budget_info = self.get_budget_info()
            if budget_info.get("is_budget_warning"):
                logger.warning(f"Budget warning: {budget_info['percentage_used']}% used ({budget_info['budget_used']}/{budget_info['budget_limit']} tokens)")
            
            return return_format

        except Exception as e:
            logger.error(f"Error generating Gemini response with new SDK: {e}")
            raise
    
    def convert_function_call_to_tool_call(self, fc: dict or Any, index: int = 0) -> Dict:
        # Converts a single function_call to tool_call-style dict
        return {
            "id": f"call_generated_{index}",
            "type": "function",
            "function": {
                "name": getattr(fc, "name"),
                "arguments": getattr(fc, "args"),
            }
        }


    async def generate_chat_response(
        self,
        messages: List[Dict[str, str]],
        **kwargs
    ) -> str:
        """Generate a chat response using Gemini's API with the new SDK."""
        if not self.client:
            raise RuntimeError("Model not initialized. Call initialize() first.")
        
        # Check budget before making request
        if not self.check_budget():
            raise RuntimeError(f"Budget limit exceeded. Used: {self.budget_used}, Limit: {self.budget_limit}")
        
        try:
            # Convert messages to the new SDK's chat history format
            # For the new SDK, chat history is directly passed to generate_content
            # or managed by a ChatSession created via client.models.start_chat()
            
            # The structure for chat history in the new SDK:
            # List of types.Content objects, where each Content has a role and parts.
            history_contents = []
            system_prompt= ""
            for msg in messages: # All except the last message
                if msg["role"] == "system":
                    system_prompt = msg["content"] 
                else:
                    role = "user" if msg["role"] == "user" else "model"
                    history_contents.append(types.Content(role=role, parts=[types.Part(text=msg["content"])]))
            
            if 'tools' in kwargs:
                tools = kwargs['tools']
            else:
                tools = []
            function_declarations_list = self.clean_and_convert_to_declarations(tools)
            tools = Tool(function_declarations=function_declarations_list)
            config = types.GenerateContentConfig(tools=[tools], 
                                                temperature=self.temperature,
                                                system_instruction=system_prompt if system_prompt else None
            )

            # Use generate_content with the full history as contents
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=history_contents, # Pass the entire conversation history
                config=config
            )

            content = response.text
            return_format = {"role":"assistant", "content": content if content is not None else "\n\n"}
            if response.function_calls is not None:
                tool_calls = []
                for cnt, fn in enumerate(response.function_calls):
                    tool_calls.append(self.convert_function_call_to_tool_call(fn, cnt))

                return_format["tool_calls"] = tool_calls

            self._update_stats(int(response.usage_metadata.prompt_token_count), int(response.usage_metadata.candidates_token_count))
            
            budget_info = self.get_budget_info()
            if budget_info.get("is_budget_warning"):
                logger.warning(f"Budget warning: {budget_info['percentage_used']}% used ({budget_info['budget_used']}/{budget_info['budget_limit']} tokens)")

            return return_format

        except Exception as e:
            logger.error(f"Error generating Gemini chat response with new SDK: {e}")
            raise
    
    async def check_availability(self) -> bool:
        """Check if Gemini API is available using the new SDK."""
        if not self.client:
            return False
        
        try:
            response = await self.client.models.generate_content(
                model=self.model_name,
                contents=[types.Part(text="Hello")],
                stream=False
            )
            return response.text is not None
        except Exception as e:
            logger.warning(f"Gemini availability check failed with new SDK: {e}")
            return False
